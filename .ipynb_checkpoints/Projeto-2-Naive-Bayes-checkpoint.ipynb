{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ps4=pd.read_excel(\"tweets_ps4.xlsx\", sheet_name=\"Treinamento\")\n",
    "\n",
    "\n",
    "def limpador(frase):\n",
    "    tweet=[]\n",
    "    frase=frase.lower()\n",
    "    frase=frase.split()\n",
    "    for j in frase:\n",
    "        if len(j)>0:\n",
    "            lista=[\",\",\";\",\"(\",\")\",\"[\",\"]\",\"\\n\",\"...\",\"***\",\".\",\"-\",\"|\"]\n",
    "            for a in lista:\n",
    "                j=j.replace(a,\" \")\n",
    "            if j[0]!=\"@\" and j[:4]!=\"http\":\n",
    "                tweet.append(j)\n",
    "    return tweet\n",
    "\n",
    "###Naive Bayes Treinamento\n",
    "\n",
    "\n",
    "# Pega os Tweets da coluna treinamento limpa eles e adiciona a uma lista chamada Frases.\n",
    "frases=[]\n",
    "for i in ps4[\"Treinamento\"]:\n",
    "    frases.append(' '.join(limpador(i)))\n",
    "\n",
    "# Substitui os Tweets \"sujos\" pelos \"limpos\", contidos na lista Frases, no DataFrame.\n",
    "for i in range(len(ps4[\"Treinamento\"])):\n",
    "    ps4[\"Treinamento\"][i]=frases[i]\n",
    "    \n",
    "# Calcula o numero de Tweets relevantes e irrelevantes \n",
    "I,R=ps4[\"Classificação\"].value_counts()\n",
    "T=I+R\n",
    "\n",
    "# print(\"Tweets Irrelevantes: \\nQuantidade: {}, Probabilidade: {} \".format(I, I/T))\n",
    "# print(\"\\n\")\n",
    "# print(\"Tweets Relevantes: \\nQuantidade: {}, Probabilidade: {} \".format(R, R/T))\n",
    "# print(\"\\n\")\n",
    "# print(\"Total={}\".format(T))\n",
    "\n",
    "\n",
    "palavrasR=[]\n",
    "palavrasI=[]\n",
    "# Separa cada palavra, dependendo da relevancia do Tweets em que está contida, e adiciona a uma lista conforme a relevancia\n",
    "# Também cria uma lista com todas as palavras.\n",
    "for i in range(len(ps4)):\n",
    "    if ps4[\"Classificação\"][i] == \"relevante\":\n",
    "        fraseSplit=ps4[\"Treinamento\"][i].split()\n",
    "        palavrasR.extend(fraseSplit)\n",
    "    else:\n",
    "        fraseSplit=ps4[\"Treinamento\"][i].split()\n",
    "        palavrasI.extend(fraseSplit)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Cria um novo dataframe com todas as palavras Relevantes e suas probabilidades.\n",
    "palavrasRDF=pd.DataFrame(data=palavrasR)\n",
    "palavrasRDF=palavrasRDF[0].value_counts().to_frame()\n",
    "palavrasRDF.columns=[\"Quantidade de Relevantes\"]\n",
    "\n",
    "\n",
    "# Cria um novo dataframe com todas as palavras Irrelevantes e suas probabilidades.\n",
    "palavrasIDF=pd.DataFrame(data=palavrasI)\n",
    "palavrasIDF=palavrasIDF[0].value_counts().to_frame()\n",
    "palavrasIDF.columns=[\"Quantidade de Irrelevantes\"]\n",
    "\n",
    "# Une os dois dataframes em um.\n",
    "palavrasDF=palavrasIDF.join(palavrasRDF, how=\"outer\").fillna(0)\n",
    "palavrasDF.sort_values(by=\"Quantidade de Irrelevantes\", ascending=False).head()\n",
    "\n",
    "\n",
    "def classificador(tweet):\n",
    "    total=len(palavrasDF)\n",
    "    somaRelevantes=sum(palavrasDF[\"Quantidade de Relevantes\"])\n",
    "    somaIrrelevantes=sum(palavrasDF[\"Quantidade de Irrelevantes\"])\n",
    "    \n",
    "    probabilidadeRelevante=1\n",
    "    probabilidadeIrrelevante=1\n",
    "    for i in limpador(tweet):\n",
    "        if i in palavrasDF.index:\n",
    "            probabilidadeRelevante*=((palavrasDF[\"Quantidade de Relevantes\"][i]+1)/(somaRelevantes+total))\n",
    "            probabilidadeIrrelevante*=((palavrasDF[\"Quantidade de Irrelevantes\"][i]+1)/(somaIrrelevantes+total))\n",
    "        else:\n",
    "            probabilidadeRelevante*=(1/(somaRelevantes+total))\n",
    "            probabilidadeIrrelevante*=(1/(somaIrrelevantes+total))\n",
    "            \n",
    "    probabilidadeRelevante*=(R/T)\n",
    "    probabilidadeIrrelevante*=(I/T)\n",
    "    \n",
    "    if probabilidadeRelevante>probabilidadeIrrelevante:\n",
    "        return \"relevante\"\n",
    "    else:\n",
    "        return \"irrelevante\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivo Falso: 4, 2.0%\n",
      "Positivo Verdadeiro: 78, 39.0%\n",
      "Negativo Verdadeiro: 98, 49.0%\n",
      "Negativo Falso: 20, 10.0%\n",
      "Porcentagem de erro do Classificador: 12.0%\n"
     ]
    }
   ],
   "source": [
    "ps4Teste=pd.read_excel(\"tweets_ps4.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "positivosFalso=0\n",
    "positivosVerdadeiro=0\n",
    "negativosVerdadeiro=0\n",
    "negativosFalso=0\n",
    "\n",
    "for k in ps4Teste.index:\n",
    "    ps4Teste[\"Classificador\"]=classificador(ps4Teste[\"Teste\"][k])\n",
    "    if ps4Teste[\"Classificação\"][k]==\"relevante\":\n",
    "        if ps4Teste[\"Classificação\"][k]==classificador(ps4Teste[\"Teste\"][k]):\n",
    "            positivosVerdadeiro+=1  \n",
    "        else:\n",
    "            positivosFalso+=1\n",
    "        \n",
    "    elif ps4Teste[\"Classificação\"][k]==\"irrelevante\":\n",
    "        if ps4Teste[\"Classificação\"][k]==classificador(ps4Teste[\"Teste\"][k]):\n",
    "            negativosVerdadeiro+=1\n",
    "        else:\n",
    "            negativosFalso+=1\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"Positivo Falso: {}, {}%\".format(positivosFalso,(positivosFalso/2)))\n",
    "print(\"Positivo Verdadeiro: {}, {}%\".format(positivosVerdadeiro,(positivosVerdadeiro/2)))\n",
    "print(\"Negativo Verdadeiro: {}, {}%\".format(negativosVerdadeiro,(negativosVerdadeiro/2)))\n",
    "print(\"Negativo Falso: {}, {}%\".format(negativosFalso,(negativosFalso/2)))\n",
    "print(\"Porcentagem de erro do Classificador: {}%\".format((positivosFalso/2)+(negativosFalso/2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "A partir das medidas mostradas acima, conlui-se que o classificador é bom, visto que mais de 80% dos tweets estão entre os verdadeiros, e apenas 12% entre os falsos. Ou seja, dentre os tweets que classificamos \"manualmente\", o classificador obteve a mesma classificação em 88% dos casos. É curioso notar que, entre os 12% dos tweets que houveram divergência entre nós e o classificador, 83%, ou seja, 20 tweets, são irrelevantes. \n",
    "   \n",
    "Um motivo que poderia explicar isso é que, um tweet que classificamos como irrelevante pode conter palavras que para o classificador são relevantes, por conta da quantidade de vezes que a mesma aparece. Nestes casos, o classificador marcará o tweet como relevante por conter tais palavras, mesmo que ele seja irrelevante.Outro motivo é que o tweet pode estar muito pequeno e conter palavras relevantes. Assim, o tweet será classificadao como relevante, mesmo que não seja. Por exemplo, no tweet \"@gristy07 @uguna_ps4 @moonjuicetv @silentkilla562 thats what they tell me\", após ser limpado, sobram apenas as palavras \"thats what they tell me\". Estas podem ter sido classificadas com uma probabilidade alta de serão relevantes, e como consequência o tweet é classificado como relevante. Entretanto, a frase foi classificada como irrelevante por nós apesar de ter palavras relevantes.\n",
    "\n",
    "As mensagens com sarcasmo não são classificadas de forma diferente. Isto ocorre pois o classificador não entende o significado da palavra. Ele apenas checa a probabilidade de ser relevante ou não. Já as palavras com dupla negação tambem são classificadas da mesma forma pois como a probabilidade de cada palavra ser relevante ou não é multiplicada por todas as palavras da frase, não importa a posição que esta palavra ocupa. Consequentemente, uma dupla negação é ignorada. Por exemplo, em um possível tweet \"I ain't got no time to play PS4\", em que há a dupla negação, esta teria a mesma probabilidade que a frase \"No. I ain't got time to play PS4\".\n",
    "\n",
    "Para melhorias futuras desse trabalho seria interresente tratar melhor os tweets antes de classifica-los. Como por exemplo remover palavras que não agregam valor semántico a frase mas que poderiam alterar bastante no classificador, como artigos e preposições. Verificar se há palavras no diminutivo, aumentativo e no plural também poderiam ajudar o classificador. Procurar por palavras sinônimas e neutras na frase, também ajudaria a criar um classificador mais preciso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

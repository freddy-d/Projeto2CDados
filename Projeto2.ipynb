{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4=pd.read_excel(\"tweets_ps4.xlsx\", sheet_name=\"Treinamento\")\n",
    "ps4Teste=pd.read_excel(\"tweets_ps4.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "def limpador(frase):\n",
    "    tweet=[]\n",
    "    frase=frase.lower()\n",
    "    frase=frase.split()\n",
    "    for j in frase:\n",
    "        if len(j)>0:\n",
    "            lista=[\",\",\";\",\"(\",\")\",\"[\",\"]\",\"\\n\",\"...\",\"***\",\".\",\"-\",\"|\"]\n",
    "            for a in lista:\n",
    "                j=j.replace(a,\" \")\n",
    "            if j[0]!=\"@\" and j[:4]!=\"http\":\n",
    "                tweet.append(j)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Naive Bayes Treinamento\n",
    "\n",
    "frases=[]\n",
    "#Pega os Tweets da coluna treinamento limpa eles e adiciona a uma lista chamada Frases.\n",
    "for i in ps4[\"Treinamento\"]:\n",
    "    frases.append(' '.join(limpador(i)))\n",
    "\n",
    "#Substitui os Tweets \"sujos\" pelos \"limpos\", contidos na lista Frases, no DataFrame.\n",
    "for i in range(len(ps4[\"Treinamento\"])):\n",
    "    ps4[\"Treinamento\"][i]=frases[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets Irrelevantes: 184\n",
      "Tweets Relevantes: 116\n",
      "Total=300\n"
     ]
    }
   ],
   "source": [
    "#Calcula o numero de Tweets relevantes e irrelevantes \n",
    "I,R=ps4[\"Classificação\"].value_counts()\n",
    "T=I+R\n",
    "print(\"Tweets Irrelevantes: {}\".format(I))\n",
    "print(\"Tweets Relevantes: {}\".format(R))\n",
    "print(\"Total={}\".format(T))\n",
    "# ps4Treina.sort_values(by=\"Classificação\").head()\n",
    "# ps4Treina.sort_values(by=\"Classificação\").tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantidade de Irrelevantes</th>\n",
       "      <th>Quantidade de Relevantes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>123.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>115.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps4</th>\n",
       "      <td>110.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>87.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>78.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quantidade de Irrelevantes  Quantidade de Relevantes\n",
       "rt                        123.0                      34.0\n",
       "the                       115.0                      73.0\n",
       "ps4                       110.0                     115.0\n",
       "a                          87.0                      49.0\n",
       "to                         78.0                      43.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavrasR=[]\n",
    "palavrasI=[]\n",
    "# Separa cada palavra, dependendo da relevancia do Tweets em que está contida, e adiciona a uma lista conforme a relevancia\n",
    "# Também cria uma lista com todas as palavras.\n",
    "for i in range(len(ps4)):\n",
    "    if ps4[\"Classificação\"][i] == \"relevante\":\n",
    "        fraseSplit=ps4[\"Treinamento\"][i].split()\n",
    "        palavrasR.extend(fraseSplit)\n",
    "    else:\n",
    "        fraseSplit=ps4[\"Treinamento\"][i].split()\n",
    "        palavrasI.extend(fraseSplit)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Cria um novo dataframe com todas as palavras Relevantes e suas probabilidades.\n",
    "palavrasRDF=pd.DataFrame(data=palavrasR)\n",
    "palavrasRDF=palavrasRDF[0].value_counts().to_frame()\n",
    "palavrasRDF.columns=[\"Quantidade de Relevantes\"]\n",
    "\n",
    "\n",
    "#Cria um novo dataframe com todas as palavras Irrelevantes e suas probabilidades.\n",
    "palavrasIDF=pd.DataFrame(data=palavrasI)\n",
    "palavrasIDF=palavrasIDF[0].value_counts().to_frame()\n",
    "palavrasIDF.columns=[\"Quantidade de Irrelevantes\"]\n",
    "\n",
    "\n",
    "palavrasDF=palavrasIDF.join(palavrasRDF, how=\"outer\").fillna(0)\n",
    "palavrasDF.sort_values(by=\"Quantidade de Irrelevantes\", ascending=False).head()\n",
    "\n",
    "#palavrasRDF.head(10)\n",
    "#palavrasIDF.head(10)\n",
    "#palavrasDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador(tweet):\n",
    "    total=len(palavrasDF)\n",
    "    somaRelevantes=sum(palavrasDF[\"Quantidade de Relevantes\"])\n",
    "    somaIrrelevantes=sum(palavrasDF[\"Quantidade de Irrelevantes\"])\n",
    "    \n",
    "    probabilidadeRelevante=1\n",
    "    probabilidadeIrrelevante=1\n",
    "    for i in limpador(tweet):\n",
    "        if i in palavrasDF.index:\n",
    "            probabilidadeRelevante*=((palavrasDF[\"Quantidade de Relevantes\"][i]+1)/(somaRelevantes+total))\n",
    "            probabilidadeIrrelevante*=((palavrasDF[\"Quantidade de Irrelevantes\"][i]+1)/(somaIrrelevantes+total))\n",
    "        else:\n",
    "            probabilidadeRelevante*=(1/(somaRelevantes+total))\n",
    "            probabilidadeIrrelevante*=(1/(somaIrrelevantes+total))\n",
    "            \n",
    "    probabilidadeRelevante*=(R/T)\n",
    "    probabilidadeIrrelevante*=(I/T)\n",
    "    \n",
    "    if probabilidadeRelevante>probabilidadeIrrelevante:\n",
    "        return \"relevante\"\n",
    "    else:\n",
    "        return \"irrelevante\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivo Falso: 4, 2.0%\n",
      "Positivo Verdadeiro: 78, 39.0%\n",
      "Negativo Verdadeiro: 98, 49.0%\n",
      "Negativo Falso: 20, 10.0%\n",
      "Porcentagem de erro do Classificador: 12.0%\n"
     ]
    }
   ],
   "source": [
    "positivosFalso=0\n",
    "positivosVerdadeiro=0\n",
    "negativosVerdadeiro=0\n",
    "negativosFalso=0\n",
    "\n",
    "for k in ps4Teste.index:\n",
    "    ps4Teste[\"Classificador\"]=classificador(ps4Teste[\"Teste\"][k])\n",
    "    if ps4Teste[\"Classificação\"][k]==\"relevante\":\n",
    "        if ps4Teste[\"Classificação\"][k]==classificador(ps4Teste[\"Teste\"][k]):\n",
    "            positivosVerdadeiro+=1  \n",
    "        else:\n",
    "            positivosFalso+=1\n",
    "        \n",
    "    elif ps4Teste[\"Classificação\"][k]==\"irrelevante\":\n",
    "        if ps4Teste[\"Classificação\"][k]==classificador(ps4Teste[\"Teste\"][k]):\n",
    "            negativosVerdadeiro+=1\n",
    "        else:\n",
    "            negativosFalso+=1\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"Positivo Falso: {}, {}%\".format(positivosFalso,(positivosFalso/2)))\n",
    "print(\"Positivo Verdadeiro: {}, {}%\".format(positivosVerdadeiro,(positivosVerdadeiro/2)))\n",
    "print(\"Negativo Verdadeiro: {}, {}%\".format(negativosVerdadeiro,(negativosVerdadeiro/2)))\n",
    "print(\"Negativo Falso: {}, {}%\".format(negativosFalso,(negativosFalso/2)))\n",
    "print(\"Porcentagem de erro do Classificador: {}%\".format((positivosFalso/2)+(negativosFalso/2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "A partir das medidas mostradas acima, conlui-se que o classificador é bom, visto que mais de 80% dos tweets estão entre os verdadeiros, e apenas 12% entre os falsos. Ou seja, dentre os tweets que classificamos \"manualmente\", o classificador obteve a mesma classificação em 88% dos casos. É curioso notar que, entre os 12% dos tweets que houveram dvergência entre nós e o classificador, 83%, ou seja, 20 tweets, são de irrelevantes. Um motivo que explica isso é que um tweet que classificamos como irrelevante pode conter palavras relevantes. Nestes casos, o classificador marcará como relevante por conter tais palavras, mesmo que seja irrelevante. Outro motivo é que o tweet pode estar muito pequeno e conter palavras relevantes. Assim, o tweet será classificadao como relevante, mesmo que não seja. Por exemplo, no tweet \"@gristy07 @uguna_ps4 @moonjuicetv @silentkilla562 thats what they tell me \", após ser limpado, sobram apenas as palavras \"thats what they tell me\". Estas podem ter sido classificadas como palavras relevantes, fazendo com que o tweet seja classificado como relevante. Entretanto, a frase foi classificada como irrelevante por nós apesar de ter palavras relevantes.\n",
    "\n",
    "As mensagens com sarcasmo não são classificadas de forma diferente. Isto ocorre pois o classificador não entende o significado da palavra. Ele apenas checa se ela é relevante ou não. Já as palavras com dupla negação tambem são classificadas da mesma forma pois como a probabilidade de cada palavra ser relevante ou não é multiplicada por todas as palavras da frase, não importa a posição que esta palavra ocupa. Consequentemente, uma dupla negação é ignorada. Por exemplo, em um possível tweet \"I ain't got no time to play PS4\",em que há a dupla negação, esta teria a mesma probabilidade que a frase \"No. I ain't got time to play PS4\".   \n",
    "\n",
    "Como um futuro plano de expansão, planejamos aumentar o número de tweets na base de dados \"treinamento\", fazendo com que mais palavras sejam classificadas entre relevantes e irrelevantes, aumentando assim a eficiência do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
